{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vectorization**\n",
    "\n",
    "**By**: Pedro Ruiz\n",
    "\n",
    "---\n",
    "\n",
    "En este notebook nos centraremos en la **vectorización** de datos, que consiste en tomar los resultados de clasificación y detección de objetos para generar representaciones vectoriales por vídeo. Estas representaciones serán utilizadas más adelante como entrada para clasificadores y sistemas de recomendación.\n",
    "\n",
    "\n",
    "Este trabajo lo dividiremos en **cuatro secciones**:\n",
    "\n",
    "1. **Importaciones**\n",
    "2. **Configuración**\n",
    "3. **Representaciones Vectoriales**\n",
    "4. **Almacenamiento de Resultados**\n",
    "\n",
    "\n",
    "## 1. Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config/settings.conf')\n",
    "\n",
    "detection_results_semantic_path = config['data']['detection_results_semantic_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Representaciones Vectoriales  \n",
    "\n",
    "### Identificación de Clases  \n",
    "\n",
    "En esta etapa, nos centraremos en **extraer todas las clases detectadas** en el proceso de clasificación. Para ello, **recorreremos los archivos CSV** y los **almacenaremos** para poder **asignarles un índice**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases encontradas: ['airplane', 'apple', 'backpack', 'banana', 'baseball bat', 'baseball glove', 'bear', 'bed', 'bench', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bowl', 'broccoli', 'bus', 'cake', 'car', 'carrot', 'cat', 'cell phone', 'chair', 'class_87', 'class_88', 'class_89', 'class_90', 'clock', 'couch', 'cow', 'cup', 'dining table', 'dog', 'donut', 'elephant', 'fire hydrant', 'frisbee', 'giraffe', 'hair drier', 'horse', 'hot dog', 'keyboard', 'kite', 'knife', 'microwave', 'motorcycle', 'mouse', 'nan', 'orange', 'oven', 'parking meter', 'person', 'pizza', 'potted plant', 'refrigerator', 'sandwich', 'sheep', 'sink', 'skateboard', 'skis', 'snowboard', 'spoon', 'sports ball', 'stop sign', 'suitcase', 'surfboard', 'teddy bear', 'tennis racket', 'toaster', 'toothbrush', 'traffic light', 'train', 'truck', 'umbrella', 'vase', 'wine glass', 'zebra']\n"
     ]
    }
   ],
   "source": [
    "categories = [dr for dr in os.listdir(detection_results_semantic_path) if os.path.isdir(os.path.join(detection_results_semantic_path, dr))]         # Lista de categorías (directorios) en la ruta de resultados semánticos\n",
    "all_classes = set()                                                                                                                                 # Conjunto para almacenar todas las clases únicas\n",
    "\n",
    "for category in categories:                                                                                                                         # Iterar sobre cada categoría\n",
    "    category_path = os.path.join(detection_results_semantic_path, category)                                                                         # Ruta completa de la categoría\n",
    "    for csv_file in os.listdir(category_path):                                                                                                      # Iterar sobre cada archivo CSV en la categoría\n",
    "        if csv_file.endswith('.csv'):                                                                                                               # Verificar si el archivo es un CSV\n",
    "            df = pd.read_csv(os.path.join(category_path, csv_file))                                                                                 # Leer el archivo CSV en un DataFrame\n",
    "            if 'object' in df.columns:                                                                                                              # Verificar si la columna 'object' existe en el DataFrame\n",
    "                df['object'] = df['object'].astype(str).fillna('unknown')                                                                           # Convertir la columna 'object' a string y llenar valores faltantes con 'unknown'\n",
    "                objs = df['object'].unique()                                                                                                        # Obtener los valores únicos de la columna 'object'\n",
    "                all_classes.update(objs)                                                                                                            # Actualizar el conjunto de todas las clases con los objetos encontrados\n",
    "            else:\n",
    "                print(f\"{csv_file} no tiene columna 'object'.\")\n",
    "\n",
    "# LKista ordenada\n",
    "all_classes = sorted(list(all_classes))                                                                                                             # Convertir el conjunto de clases a una lista ordenada\n",
    "class_to_idx = {c: i for i, c in enumerate(all_classes)}                                                                                            # Crear un diccionario que mapea cada clase a un índice\n",
    "\n",
    "print(f\"Clases encontradas: {all_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de Vectores  \n",
    "\n",
    "A continuación, generamos un **vector de características** para cada uno de los vídeos. Cada posición corresponde a una **clase identificada**, y su valor dependerá de:  \n",
    "\n",
    "- La **frecuencia** con la que apareció cada objeto.  \n",
    "- La **confianza** de la detección.  \n",
    "- El **área promedio** del objeto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se calcularon vectores para 300 vídeos.\n"
     ]
    }
   ],
   "source": [
    "video_features = []\n",
    "video_labels = []\n",
    "\n",
    "for category in categories:                                                             # Iteramos  sobre las categoría\n",
    "    category_path = os.path.join(detection_results_semantic_path, category)             # y creamos la ruta.\n",
    "    for csv_file in os.listdir(category_path):                                          # Iteramoes sobre cada archivo CSV,\n",
    "        if csv_file.endswith('.csv'):                                                   # verificando que sean CSVs\n",
    "            video_name = csv_file.replace('.csv', '')                                   # extraemos el nombre del video\n",
    "            df = pd.read_csv(os.path.join(category_path, csv_file))                     # y los leemos.\n",
    "            \n",
    "            # Comprobación de columnas 'object' y gestión de valores faltantes\n",
    "            if 'object' in df.columns:\n",
    "                df['object'] = df['object'].astype(str).fillna('unknown')\n",
    "            else:\n",
    "                print(f\"Advertencia: {csv_file} no contiene la columna 'object'. Aplicando 'unknown' sobre todos los objetos.\") \n",
    "                df['object'] = 'unknown'\n",
    "            \n",
    "            # Crear vector de features\n",
    "            vec = np.zeros(len(all_classes), dtype=float)                               # Inicializamos un vector de ceros para todas las clases\n",
    "            \n",
    "            # Agrupar por objeto\n",
    "            class_groups = df.groupby('object')                                         # Agrupamos el conjunto por la columna 'object'\n",
    "            for obj, group in class_groups:                                             # e iteramos sobre cada grupo de objetos\n",
    "                idx = class_to_idx.get(obj, None)                                       # extraemos el índice del objeto en el diccionario class_to_idx\n",
    "                if idx is not None:                                                     # Verificamos que el objeto exista en el diccionario\n",
    "                    freq = len(group)                                                   # y calculamos la frecuencia de aparición, la confianza promedio y el área promedio.\n",
    "                    mean_conf = group['score'].mean() if 'score' in group.columns else 0.0\n",
    "                    mean_area = group['area'].mean() if 'area' in group.columns else 0.0\n",
    "                    importance = freq * mean_conf * (mean_area / (224*224))             # Ademas, incorporamos el calculo de la importancia normalizando el área\n",
    "                    vec[idx] = importance                                               # y la asignamos al vector en la posición del índice.\n",
    "                else:\n",
    "                    print(f\"'{obj}' no encontrado en class_to_idx.\")\n",
    "            \n",
    "            # Guardar el vector\n",
    "            video_features.append([category, video_name] + vec.tolist())                # Añadir el vector de características a la lista video_features\n",
    "            video_labels.append(category)                                               # Añadir la categoría a la lista video_labels\n",
    "\n",
    "print(f\"Se calcularon vectores para {len(video_features)} vídeos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Almacenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectores guardados en ../data/video_features.csv\n"
     ]
    }
   ],
   "source": [
    "columns = ['category','video_name'] + all_classes\n",
    "vectors_df = pd.DataFrame(video_features, columns=columns)\n",
    "output_vector_path = \"../data/video_features.csv\"\n",
    "vectors_df.to_csv(output_vector_path, index=False)\n",
    "print(f\"Vectores guardados en {output_vector_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
